# Config file for autoencoder training

nbars: 4 # Number of bars in the input
nsources : 8 # Number of audios in the input - because semantics this should be 2 times that
num_workers_ds : 0 # Number of workers for loading the dataset
dataset_dir: "E:/audio-dataset-v3" # Directory containing the dataset
output_dir: "E:/output" # Directory to save the trained models and checkpoints
val_count: 100 # Number of validation samples
sample_rate: 48000 # Sample rate of the audio
ntimeframes: 768
nfft: 1025 # FFT size for spectrogram

z_channels: 4 # Number of channels in the latent space
codebook_size: 1024 # Size of each codebook for VQ-VAE
nquantizers: 4 # Number of quantizers
down_channels : [32, 64, 128, 128] # Number of channels in each downsampling layer
mid_channels : [128, 128] # Number of channels in each middle layer
down_sample : [2, 2, 4] # Downsampling factors for each downsampling layer
attn_down : [False, False, False] # Whether to use attention in each downsampling layer
norm_channels: 32 # Number of channels for normalization
num_heads: 4 # Number of attention heads
num_down_layers : 2 # Number of downsampling layers
num_mid_layers : 2 # Number of middle layers
num_up_layers : 2 # Number of upsampling layers
gradient_checkpointing : True # Whether to use gradient checkpointing

seed : 1943 # Random seed
num_workers_dl: 1 # Number of workers for data loading
batch_size: 1 # Batch size for autoencoder training
disc_start: 1024     # Start training discriminator after this many steps. Set to a very small number for testing
disc_spec_weight: 0.5      # Weight of discriminator loss
disc_audio_weights: [1, 1, 1, 1] # Weights for each audio discriminator
codebook_weight: 1    # Weight of codebook loss
commitment_beta: 0.2
perceptual_weight: 1 # Weight for the perceptual loss
steps: 30000 # Number of training steps to perform in total
autoencoder_lr: 0.00001 # Learning rate for the autoencoder
autoencoder_acc_steps: 16 # Number of accumulation steps for the autoencoder
ndiscriminators: 4 # Number of audio discriminaotrs
nfilters: 1024 # Number of filters in the audio discriminators
naudio_disc_layers: 4 # Number of layers in each audio discriminaotrs
audio_disc_downsampling_factor: 4 # Down sampling factor between each audio discriminator
nspec_disc_patches: 4 # Number of time patches to operate with in the spectrogrm disciminaotr
save_steps: 512 # Number of steps between saving images
vqvae_autoencoder_ckpt_name: 'vqvae_autoencoder_ckpt.pth' # Checkpoint name for the VQ-VAE autoencoder
run_name: "vqvae-training" # Name of the training run
disc_loss: "bce" # Type of discriminator loss: "bce", "mse"
val_steps: 512 # Number of steps between validations
